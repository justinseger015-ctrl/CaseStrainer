#!/usr/bin/env python3
"""
Comprehensive test script for the full CaseStrainer pipeline:
1. Case name and year extraction
2. Citation verification 
3. Parallel citation clustering
"""

import sys
import os
import json
import re

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from standalone_citation_parser import CitationParser
from enhanced_courtlistener_verification import EnhancedCourtListenerVerifier
from enhanced_sync_processor import EnhancedSyncProcessor, ProcessingOptions

def test_case_name_extraction():
    """Test case name and year extraction."""
    print("=== Test 1: Case Name and Year Extraction ===")
    
    parser = CitationParser()
    
    # Test text with parallel citations
    test_text = """A federal court may ask this court to answer a question of Washington law when a resolution of that question is necessary to resolve a case before the federal court. RCW 2.60.020; Convoyant, LLC v. DeepThink, LLC, 200 Wn.2d 72, 73, 514 P.3d 643 (2022). Certified questions are questions of law we review de novo. Carlson v. Glob. Client Sols., LLC, 171 Wn.2d 486, 493, 256 P.3d 321 (2011). We also review the meaning of a statute de novo. Dep't of Ecology v. Campbell & Gwinn, LLC, 146 Wn.2d 1, 9, 43 P.3d 4 (2003)"""
    
    # Expected parallel citations:
    # 1. 200 Wn.2d 72 and 514 P.3d 643 (same case: Convoyant, LLC v. DeepThink, LLC)
    # 2. 171 Wn.2d 486 and 256 P.3d 321 (same case: Carlson v. Glob. Client Sols., LLC)  
    # 3. 146 Wn.2d 1 and 43 P.3d 4 (same case: Dep't of Ecology v. Campbell & Gwinn, LLC)
    
    print(f"Test text: {test_text[:100]}...")
    print()
    
    # Extract citations using regex patterns
    citation_patterns = [
        r'\b\d+\s+[A-Za-z.]+(?:\s+\d+)?\b',  # Basic citation pattern
        r'\b\d+\s+(?:Wash\.|Wn\.|P\.|A\.|S\.|N\.|F\.|U\.S\.)\b',  # Common reporters
    ]
    
    citations = []
    for pattern in citation_patterns:
        matches = re.findall(pattern, test_text)
        citations.extend(matches)
    
    # Remove duplicates and filter for Washington citations
    citations = list(set([c for c in citations if 'Wn.' in c]))
    print(f"Found {len(citations)} Washington citations:")
    
    results = []
    for citation in citations:
        result = parser.extract_from_text(test_text, citation)
        case_name = result.get('case_name')
        year = result.get('year')
        
        print(f"  {citation}: {case_name} ({year})")
        results.append({
            'citation': citation,
            'case_name': case_name,
            'year': year
        })
    
    print()
    return results

def test_citation_verification():
    """Test citation verification with CourtListener API."""
    print("=== Test 2: Citation Verification ===")
    
    # Get API key from environment
    api_key = os.getenv('COURTLISTENER_API_KEY', 'test_key_for_debugging')
    verifier = EnhancedCourtListenerVerifier(api_key)
    
    # Test cases from our extraction
    test_cases = [
        {
            'citation': '200 Wn.2d 72',
            'case_name': 'Convoyant, LLC v. DeepThink, LLC',
            'year': '2022'
        },
        {
            'citation': '171 Wn.2d 486', 
            'case_name': 'Carlson v. Glob. Client Sols., LLC',
            'year': '2011'
        },
        {
            'citation': '146 Wn.2d 1',
            'case_name': "Dep't of Ecology v. Campbell & Gwinn, LLC", 
            'year': '2003'
        }
    ]
    
    verification_results = []
    
    for test_case in test_cases:
        citation = test_case['citation']
        case_name = test_case['case_name']
        year = test_case['year']
        
        print(f"\n--- Verifying: {citation} ---")
        print(f"Case name: {case_name}")
        print(f"Year: {year}")
        
        try:
            if api_key == 'test_key_for_debugging':
                print("‚ö†Ô∏è  Using test API key - skipping actual verification")
                result = {
                    'verified': False,
                    'canonical_name': case_name,
                    'canonical_date': year,
                    'source': 'test_mode',
                    'validation_method': 'test_mode',
                    'confidence': 0.0
                }
            else:
                result = verifier.verify_citation_enhanced(citation, case_name)
            
            print(f"Verification result:")
            print(f"  Verified: {result.get('verified')}")
            print(f"  Canonical name: {result.get('canonical_name')}")
            print(f"  Canonical date: {result.get('canonical_date')}")
            print(f"  Source: {result.get('source')}")
            print(f"  Confidence: {result.get('confidence')}")
            
            verification_results.append({
                'citation': citation,
                'case_name': case_name,
                'year': year,
                'verification': result
            })
            
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
            verification_results.append({
                'citation': citation,
                'case_name': case_name,
                'year': year,
                'verification': {'error': str(e)}
            })
    
    print()
    return verification_results

def test_parallel_citation_clustering():
    """Test parallel citation clustering."""
    print("=== Test 3: Parallel Citation Clustering ===")
    
    # Create processor
    options = ProcessingOptions(
        enable_async_verification=False,  # Disable async for testing
        enable_enhanced_verification=False,
        enable_confidence_scoring=True
    )
    processor = EnhancedSyncProcessor(options)
    
    # Test text with parallel citations
    test_text = """A federal court may ask this court to answer a question of Washington law when a resolution of that question is necessary to resolve a case before the federal court. RCW 2.60.020; Convoyant, LLC v. DeepThink, LLC, 200 Wn.2d 72, 73, 514 P.3d 643 (2022). Certified questions are questions of law we review de novo. Carlson v. Glob. Client Sols., LLC, 171 Wn.2d 486, 493, 256 P.3d 321 (2011). We also review the meaning of a statute de novo. Dep't of Ecology v. Campbell & Gwinn, LLC, 146 Wn.2d 1, 9, 43 P.3d 4 (2003)"""
    
    print(f"Processing text for clustering...")
    print(f"Expected: 3 clusters with 2 citations each")
    print()
    
    try:
        # Process the text
        result = processor.process_any_input_enhanced(test_text, 'text', {})
        
        if not result.get('success'):
            print(f"‚ùå Processing failed: {result.get('error')}")
            return None
        
        # Check results
        citations = result.get('citations', [])
        clusters = result.get('clusters', [])
        
        print(f"‚úÖ Processing successful")
        print(f"üìä Found {len(citations)} citations")
        print(f"üìä Created {len(clusters)} clusters")
        print()
        
        # Expected: 3 clusters (as originally requested by user: "three clusters of two citations each")
        # 1. "Convoyant, LLC v. DeepThink, LLC" (2022) - 2 citations: 200 Wn.2d 72 and 514 P.3d 643
        # 2. "Carlson v. Glob. Client Sols., LLC" (2011) - 2 citations: 171 Wn.2d 486 and 256 P.3d 321  
        # 3. "Dep't of Ecology v. Campbell & Gwinn, LLC" (2003) - 2 citations: 146 Wn.2d 1 and 43 P.3d 4
        
        expected_clusters = 3
        expected_citations_per_cluster = 2
        
        print("=== Expected vs Actual ===")
        print(f"Expected clusters: {expected_clusters}")
        print(f"Actual clusters: {len(clusters)}")
        print(f"Expected citations per cluster: {expected_citations_per_cluster}")
        print()
        
        # Analyze each cluster
        print("=== Cluster Analysis ===")
        for i, cluster in enumerate(clusters):
            case_name = cluster.get('case_name', 'Unknown')
            year = cluster.get('year', 'Unknown')
            size = cluster.get('size', 0)
            citations_list = cluster.get('citations', [])
            
            print(f"Cluster {i+1}: {case_name} ({year})")
            print(f"  Size: {size} citations")
            print(f"  Citations: {citations_list}")
            print()
        
        # Check if clustering is correct
        if len(clusters) == expected_clusters:
            print("‚úÖ Correct number of clusters created")
        else:
            print(f"‚ùå Wrong number of clusters. Expected {expected_clusters}, got {len(clusters)}")
        
        # Check if each cluster has the right number of citations
        correct_sizes = True
        for i, cluster in enumerate(clusters):
            if cluster.get('size', 0) != expected_citations_per_cluster:
                print(f"‚ùå Cluster {i+1} has wrong size. Expected {expected_citations_per_cluster}, got {cluster.get('size', 0)}")
                correct_sizes = False
        
        if correct_sizes:
            print("‚úÖ All clusters have correct size")
        
        return {
            'citations': citations,
            'clusters': clusters,
            'success': True
        }
        
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """Run all tests."""
    print("üöÄ CaseStrainer Full Pipeline Test")
    print("=" * 80)
    print()
    
    # Test 1: Case name extraction
    extraction_results = test_case_name_extraction()
    
    # Test 2: Citation verification  
    verification_results = test_citation_verification()
    
    # Test 3: Parallel citation clustering
    clustering_results = test_parallel_citation_clustering()
    
    # Summary
    print("=== FINAL SUMMARY ===")
    print(f"‚úÖ Case name extraction: {len(extraction_results)} citations found")
    print(f"‚úÖ Citation verification: {len(verification_results)} citations processed")
    
    if clustering_results and clustering_results.get('success'):
        print(f"‚úÖ Parallel citation clustering: {len(clustering_results['clusters'])} clusters created")
    else:
        print("‚ùå Parallel citation clustering: Failed")
    
    print()
    print("üéØ Pipeline Status:")
    
    # Check if all components are working
    extraction_working = len(extraction_results) > 0
    verification_working = len(verification_results) > 0
    clustering_working = clustering_results and clustering_results.get('success')
    
    if extraction_working:
        print("  ‚úÖ Case name and year extraction: WORKING")
    else:
        print("  ‚ùå Case name and year extraction: FAILED")
    
    if verification_working:
        print("  ‚úÖ Citation verification: WORKING")
    else:
        print("  ‚ùå Citation verification: FAILED")
    
    if clustering_working:
        print("  ‚úÖ Parallel citation clustering: WORKING")
    else:
        print("  ‚ùå Parallel citation clustering: FAILED")
    
    if extraction_working and verification_working and clustering_working:
        print("\nüéâ ALL SYSTEMS OPERATIONAL! The CaseStrainer pipeline is working correctly.")
    else:
        print("\n‚ö†Ô∏è  Some components need attention. Check the detailed output above.")

if __name__ == "__main__":
    main()
