#!/usr/bin/env python3
"""
Comprehensive test of the complete backend pipeline to ensure all fields are populated.
This tests the full flow from text input to verified citations with complete metadata.
"""

import sys
import os
import json

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_complete_backend():
    """Test the complete backend pipeline end-to-end."""
    print("üß™ Testing Complete Backend Pipeline")
    print("=" * 60)
    
    # Set Redis URL for async verification
    os.environ['REDIS_URL'] = 'redis://:caseStrainerRedis123@localhost:6380/0'
    
    try:
        # Import the enhanced sync processor
        from enhanced_sync_processor import EnhancedSyncProcessor
        
        # Initialize the processor
        processor = EnhancedSyncProcessor()
        
        # Test paragraph with multiple parallel citations
        test_text = """A federal court may ask this court to answer a question of Washington law when a resolution of that question is necessary to resolve a case before the federal court. RCW 2.60.020; Convoyant, LLC v. DeepThink, LLC, 200 Wn.2d 72, 73, 514 P.3d 643 (2022). Certified questions are questions of law we review de novo. Carlson v. Glob. Client Sols., LLC, 171 Wn.2d 486, 493, 256 P.3d 321 (2011). We also review the meaning of a statute de novo. Dep't of Ecology v. Campbell & Gwinn, LLC, 146 Wn.2d 1, 9, 43 P.3d 4 (2003)"""
        
        print(f"üìù Test Text:")
        print(f"   {test_text[:100]}...")
        print()
        
        print("üîÑ Processing through Enhanced Sync Processor...")
        
        # Process the text through the complete pipeline
        result = processor.process_any_input_enhanced(
            input_data=test_text,
            input_type="text",
            options={
                "enable_enhanced_verification": True,
                "enable_clustering": True,
                "request_id": "test_complete_backend_001"
            }
        )
        
        print("‚úÖ Processing completed!")
        print()
        
        # Analyze the results
        print("üìä COMPLETE BACKEND ANALYSIS:")
        print("=" * 60)
        
        # Check overall success
        print(f"üéØ Overall Success: {result.get('success', 'N/A')}")
        print(f"üîÑ Processing Strategy: {result.get('processing_strategy', 'N/A')}")
        print(f"üìä Extraction Method: {result.get('extraction_method', 'N/A')}")
        print(f"‚è±Ô∏è  Processing Time: {result.get('processing_time', 'N/A')}")
        print(f"üìè Text Length: {result.get('text_length', 'N/A')}")
        print()
        
        # Check citations
        if 'citations' in result:
            citations = result['citations']
            print(f"üìã Citations Found: {len(citations)}")
            print()
            
            # Analyze each citation for field completeness
            for i, citation in enumerate(citations, 1):
                print(f"üîç Citation {i}: {citation.get('citation', 'N/A')}")
                print(f"   üìù Extracted Case Name: {citation.get('extracted_case_name', 'N/A')}")
                print(f"   üìÖ Extracted Date: {citation.get('extracted_date', 'N/A')}")
                print(f"   üéØ Canonical Case Name: {citation.get('canonical_name', 'N/A')}")
                print(f"   üìÖ Canonical Date: {citation.get('canonical_date', 'N/A')}")
                print(f"   üîó Canonical URL: {citation.get('canonical_url', 'N/A')}")
                print(f"   ‚úÖ Verified: {citation.get('verified', 'N/A')}")
                print(f"   üéØ Confidence: {citation.get('confidence_score', 'N/A')}")
                print(f"   üè∑Ô∏è  Extraction Method: {citation.get('extraction_method', 'N/A')}")
                print(f"   üìö Source: {citation.get('source', 'N/A')}")
                print(f"   üîç Validation Method: {citation.get('validation_method', 'N/A')}")
                print(f"   üìä Verification Confidence: {citation.get('verification_confidence', 'N/A')}")
                print()
                
                # Check for missing critical fields
                missing_fields = []
                if not citation.get('extracted_case_name'):
                    missing_fields.append('extracted_case_name')
                if not citation.get('extracted_date'):
                    missing_fields.append('extracted_date')
                if not citation.get('canonical_name'):
                    missing_fields.append('canonical_name')
                if not citation.get('canonical_date'):
                    missing_fields.append('canonical_date')
                if not citation.get('canonical_url'):
                    missing_fields.append('canonical_url')
                
                if missing_fields:
                    print(f"   ‚ö†Ô∏è  Missing Critical Fields: {', '.join(missing_fields)}")
                else:
                    print(f"   ‚úÖ All Critical Fields Present")
                print()
        
        # Check clusters
        if 'clusters' in result:
            clusters = result['clusters']
            print(f"üéØ Clusters Created: {len(clusters)}")
            print()
            
            for i, cluster in enumerate(clusters, 1):
                print(f"üì¶ Cluster {i}: {cluster.get('case_name', 'N/A')} ({cluster.get('year', 'N/A')})")
                print(f"   üìä Size: {cluster.get('size', 'N/A')} citations")
                print(f"   üè∑Ô∏è  Type: {cluster.get('cluster_type', 'N/A')}")
                print(f"   üéØ Confidence: {cluster.get('confidence_score', 'N/A')}")
                print(f"   üìù Extracted Case Name: {cluster.get('extracted_case_name', 'N/A')}")
                print(f"   üìÖ Extracted Date: {cluster.get('extracted_date', 'N/A')}")
                print(f"   üéØ Canonical Case Name: {cluster.get('canonical_name', 'N/A')}")
                print(f"   üìÖ Canonical Date: {cluster.get('canonical_date', 'N/A')}")
                print(f"   ‚úÖ Verified: {cluster.get('verified', 'N/A')}")
                print(f"   üìö Source: {cluster.get('source', 'N/A')}")
                print(f"   üîç Validation Method: {cluster.get('validation_method', 'N/A')}")
                print(f"   üéØ Citations: {', '.join(cluster.get('citations', []))}")
                print()
        
        # Check verification status
        if 'verification_status' in result:
            verification_status = result['verification_status']
            print(f"üîç Verification Status:")
            print(f"   üìã Queued: {verification_status.get('verification_queued', 'N/A')}")
            print(f"   üÜî Job ID: {verification_status.get('verification_job_id', 'N/A')}")
            print(f"   üìö Queue: {verification_status.get('verification_queue', 'N/A')}")
            print(f"   üí¨ Message: {verification_status.get('message', 'N/A')}")
            if 'error' in verification_status:
                print(f"   ‚ùå Error: {verification_status.get('error', 'N/A')}")
            print()
        
        # Check processing metadata
        if 'metadata' in result:
            metadata = result['metadata']
            print(f"üìä Processing Metadata:")
            for key, value in metadata.items():
                print(f"   {key}: {value}")
            print()
        
        # Summary analysis
        print("üìà FIELD COMPLETENESS ANALYSIS:")
        print("=" * 60)
        
        total_citations = len(result.get('citations', []))
        verified_citations = sum(1 for c in result.get('citations', []) if c.get('verified'))
        citations_with_names = sum(1 for c in result.get('citations', []) if c.get('extracted_case_name'))
        citations_with_dates = sum(1 for c in result.get('citations', []) if c.get('extracted_date'))
        citations_with_canonical_names = sum(1 for c in result.get('citations', []) if c.get('canonical_name'))
        citations_with_canonical_dates = sum(1 for c in result.get('citations', []) if c.get('canonical_date'))
        citations_with_urls = sum(1 for c in result.get('citations', []) if c.get('canonical_url'))
        
        print(f"üìä Total Citations: {total_citations}")
        print(f"‚úÖ Verified Citations: {verified_citations}/{total_citations} ({verified_citations/total_citations*100:.1f}%)")
        print(f"üìù With Extracted Names: {citations_with_names}/{total_citations} ({citations_with_names/total_citations*100:.1f}%)")
        print(f"üìÖ With Extracted Dates: {citations_with_dates}/{total_citations} ({citations_with_dates/total_citations*100:.1f}%)")
        print(f"üéØ With Canonical Names: {citations_with_canonical_names}/{total_citations} ({citations_with_canonical_names/total_citations*100:.1f}%)")
        print(f"üìÖ With Canonical Dates: {citations_with_canonical_dates}/{total_citations} ({citations_with_canonical_dates/total_citations*100:.1f}%)")
        print(f"üîó With Canonical URLs: {citations_with_urls}/{total_citations} ({citations_with_urls/total_citations*100:.1f}%)")
        print()
        
        # Overall assessment
        if verified_citations == total_citations and citations_with_canonical_names == total_citations:
            print("üéâ EXCELLENT: All citations verified with complete metadata!")
        elif verified_citations > total_citations * 0.5:
            print("‚úÖ GOOD: Most citations verified, some metadata missing")
        else:
            print("‚ö†Ô∏è  NEEDS IMPROVEMENT: Many citations not verified or missing metadata")
        
        print(f"\nüîç FULL RESULT STRUCTURE:")
        print("=" * 60)
        print(json.dumps(result, indent=2, default=str))
        
    except Exception as e:
        print(f"‚ùå Complete backend test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_complete_backend()
