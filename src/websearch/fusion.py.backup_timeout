"""
Result Fusion Module
Advanced result fusion with cross-validation and confidence scoring.
"""

from typing import Any, Dict, List, Optional
from difflib import SequenceMatcher
from urllib.parse import urlparse

from .semantic import SemanticMatcher


class ResultFusionEngine:
    """Advanced result fusion with cross-validation and confidence scoring."""
    
    def __init__(self, semantic_matcher: SemanticMatcher):
        self.semantic_matcher = semantic_matcher
    
    def fuse_results(self, results: List[Dict], query_citation: str, query_case_name: Optional[str] = None) -> List[Dict]:
        """Fuse and rank results from multiple sources."""
        if not results:
            return []
        
        url_groups = self._group_by_url_similarity(results)
        
        fused_results = []
        for group in url_groups:
            fused_result = self._fuse_result_group(group, query_citation, query_case_name)
            if fused_result:
                fused_results.append(fused_result)
        
        for result in fused_results:
            result['reliability_score'] = self._calculate_reliability_score(result, query_citation, query_case_name)
            if query_case_name:
                result['semantic_score'] = self.semantic_matcher.calculate_similarity(
                    result.get('title', ''), query_case_name
                )
        
        fused_results.sort(key=lambda r: (r.get('reliability_score', 0) + r.get('semantic_score', 0)) / 2, reverse=True)
        
        return fused_results
    
    def _group_by_url_similarity(self, results: List[Dict]) -> List[List[Dict]]:
        """Group results by URL similarity."""
        groups = []
        used_indices = set()
        
        for i, result1 in enumerate(results):
            if i in used_indices:
                continue
            
            group = [result1]
            used_indices.add(i)
            
            for j, result2 in enumerate(results[i+1:], i+1):
                if j in used_indices:
                    continue
                
                if self._are_urls_similar(result1.get('url', ''), result2.get('url', '')):
                    group.append(result2)
                    used_indices.add(j)
            
            groups.append(group)
        
        return groups
    
    def _are_urls_similar(self, url1: str, url2: str, threshold: float = 0.8) -> bool:
        """Check if two URLs are similar enough to be considered the same resource."""
        if not url1 or not url2:
            return False
        
        try:
            parsed1 = urlparse(url1)
            parsed2 = urlparse(url2)
            
            if parsed1.netloc != parsed2.netloc:
                return False
            
            path_similarity = SequenceMatcher(None, parsed1.path, parsed2.path).ratio()
            return path_similarity >= threshold
        
        except Exception:
            return False
    
    def _fuse_result_group(self, group: List[Dict], query_citation: str, query_case_name: Optional[str] = None) -> Optional[Dict]:
        """Fuse a group of similar results into a single result."""
        if not group:
            return None
        
        if len(group) == 1:
            return group[0]
        
        base_result = max(group, key=lambda r: r.get('reliability_score', 0))
        
        fused = base_result.copy()
        
        titles = [r.get('title', '') for r in group if r.get('title')]
        if titles:
            if query_case_name:
                best_title, score = self.semantic_matcher.find_best_match(query_case_name, titles)
                fused['title'] = best_title or max(titles, key=len)
            else:
                fused['title'] = max(titles, key=len)
        
        snippets = [r.get('snippet', '') for r in group if r.get('snippet')]
        fused['snippet'] = max(snippets, key=len) if snippets else ''
        
        sources = list(set(r.get('source', '') for r in group if r.get('source')))
        fused['source'] = " + ".join(sources[:3])  # Limit to 3 sources
        
        scores = [r.get('reliability_score', 0) for r in group]
        fused['reliability_score'] = sum(scores) / len(scores)
        
        fused['fusion_metadata'] = {
            'group_size': len(group),
            'original_sources': sources,
            'fusion_method': 'semantic_grouping'
        }
        
        return fused
    
    def _calculate_reliability_score(self, result: Dict, query_citation: str, query_case_name: Optional[str] = None) -> float:
        """Calculate reliability score for a result."""
        score = 0.0
        
        score += result.get('reliability_score', 0) * 0.3
        
        source_scores = {
            'justia': 0.9,
            'findlaw': 0.85,
            'courtlistener': 0.9,
            'leagle': 0.8,
            'casetext': 0.75,
            'vlex': 0.7,
            'google scholar': 0.6,
            'bing': 0.4,
            'duckduckgo': 0.4,
        }
        
        source_score = 0.0
        source = result.get('source', '').lower()
        for source_name, weight in source_scores.items():
            if source_name in source:
                source_score = max(source_score, weight)
        score += source_score * 0.3
        
        if query_citation:
            citation_text = f"{result.get('title', '')} {result.get('snippet', '')}"
            if query_citation.lower() in citation_text.lower():
                score += 0.2
        
        if query_case_name and result.get('title'):
            name_similarity = self.semantic_matcher.calculate_similarity(result['title'], query_case_name)
            score += name_similarity * 0.2
        
        return min(1.0, score) 