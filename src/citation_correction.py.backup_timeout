
"""
Citation Correction Suggestions

This module provides functionality to suggest corrections for unconfirmed citations
by finding similar verified citations and providing "did you mean" alternatives.
"""

import re
import json
import os
import requests
import logging

logger = logging.getLogger(__name__)

try:
    from fuzzywuzzy import fuzz  # type: ignore
except ImportError:
    def fuzz_ratio(s1, s2):
        if not s1 or not s2:
            return 0
        s1, s2 = s1.lower(), s2.lower()
        if s1 == s2:
            return 100
        common_chars = sum(1 for c in s1 if c in s2)
        return int((common_chars / max(len(s1), len(s2))) * 100)
    
    class fuzz:
        @staticmethod
        def ratio(s1, s2):
            return fuzz_ratio(s1, s2)

DOWNLOAD_DIR = "downloaded_briefs"
UNCONFIRMED_CITATIONS_FILE = os.path.join(
    DOWNLOAD_DIR, "unconfirmed_citations_flat.json"
)
CORRECTION_CACHE_FILE = os.path.join(DOWNLOAD_DIR, "correction_suggestions.json")

COURTLISTENER_API_URL = "https://www.courtlistener.com/api/rest/v4/search/"


def load_api_key():
    try:
        with open("config.json", "r") as f:
            config = json.load(f)
            return config.get("courtlistener_api_key")
    except Exception as e:
        logger.error(f"Error loading API key: {e}")
        return None


def load_unconfirmed_citations():
    """Load unconfirmed citations from the JSON file."""
    try:
        if os.path.exists(UNCONFIRMED_CITATIONS_FILE):
            with open(UNCONFIRMED_CITATIONS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        return []
    except Exception as e:
        logger.error(f"Error loading unconfirmed citations: {e}")
        return []


def load_correction_cache():
    """Load correction suggestions from cache."""
    try:
        if os.path.exists(CORRECTION_CACHE_FILE):
            with open(CORRECTION_CACHE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}
    except Exception as e:
        logger.error(f"Error loading correction cache: {e}")
        return {}


def save_correction_cache(cache):
    """Save correction suggestions to cache."""
    try:
        with open(CORRECTION_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache, f, indent=2)
        logger.info(f"Saved correction suggestions to {CORRECTION_CACHE_FILE}")
    except Exception as e:
        logger.error(f"Error saving correction cache: {e}")


def extract_citation_components(citation_text):
    """Extract components from a citation for better matching."""
    components = {}

    volume_match = re.search(r"(\d+)\s+", citation_text)
    if volume_match:
        components["volume"] = volume_match.group(1)

    reporter_match = re.search(r"([A-Za-z]+\.(?:\s*\d+)?[A-Za-z]*)", citation_text)
    if reporter_match:
        components["reporter"] = reporter_match.group(1)

    page_match = re.search(r",\s*(\d+)", citation_text)
    if page_match:
        components["page"] = page_match.group(1)

    year_match = re.search(r"\((\d{4})\)", citation_text)
    if year_match:
        components["year"] = year_match.group(1)

    wl_match = re.search(r"(\d{4})\s+WL\s+(\d+)", citation_text)
    if wl_match:
        components["wl_year"] = wl_match.group(1)
        components["wl_number"] = wl_match.group(2)

    return components


def find_similar_citations(citation_text, api_key=None):
    """Find similar citations using the CourtListener API and local database."""
    cache = load_correction_cache()
    if citation_text in cache:
        logger.info(f"Using cached suggestions for {citation_text}")
        return cache[citation_text]

    suggestions = []

    components = extract_citation_components(citation_text)

    if api_key:
        try:
            query_parts = []
            if "volume" in components:
                query_parts.append(components["volume"])
            if "reporter" in components:
                query_parts.append(components["reporter"])

            if "wl_year" in components and "wl_number" in components:
                query_parts = [f"{components['wl_year']} WL {components['wl_number']}"]

            query = " ".join(query_parts)

            if query:
                headers = {
                    "Authorization": f"Token {api_key}",
                    "Content-Type": "application/json",
                }

                params = {
                    "q": query,
                    "type": "o",  # Opinion type
                    "order_by": "score desc",  # Order by relevance
                    "page_size": 5,  # Limit to 5 results
                }

                logger.info(f"Searching CourtListener API for: {query}")
                response = requests.get(
                    COURTLISTENER_API_URL, headers=headers, params=params, timeout=30
                )

                if response.status_code == 200:
                    data = response.json()
                    results = data.get("results", [])

                    for result in results:
                        case_name = result.get("case_name", "")
                        citation = result.get("citation", "")
                        url = f"https://www.courtlistener.com{result.get('absolute_url', '')}"

                        if citation:
                            similarity = fuzz.ratio(
                                citation_text,
                                citation,
                            )

                            if similarity > 60:  # Only include if reasonably similar
                                suggestions.append(
                                    {
                                        "citation": citation,
                                        "case_name": case_name,
                                        "url": url,
                                        "similarity": similarity,
                                        "source": "CourtListener API",
                                    }
                                )
        except Exception as e:
            logger.error(f"Error searching CourtListener API: {e}")

    unconfirmed_citations = load_unconfirmed_citations()
    confirmed_citations = [
        c for c in unconfirmed_citations if c.get("confidence", 0) >= 0.7
    ]

    for citation in confirmed_citations:
        confirmed_text = citation.get("citation_text", "")
        if confirmed_text:
            similarity = fuzz.ratio(
                citation_text, confirmed_text
            )

            confirmed_components = extract_citation_components(confirmed_text)
            component_match = False

            if "reporter" in components and "reporter" in confirmed_components:
                if components["reporter"] == confirmed_components["reporter"]:
                    component_match = True

            if (
                "wl_year" in components
                and "wl_year" in confirmed_components
                and components["wl_year"] == confirmed_components["wl_year"]
            ):
                component_match = True

            if similarity > 60 or component_match:
                suggestions.append(
                    {
                        "citation": confirmed_text,
                        "case_name": citation.get("case_name", ""),
                        "url": citation.get("court_listener_url", ""),
                        "similarity": similarity,
                        "source": "Local Database",
                    }
                )

    suggestions.sort(key=lambda x: x["similarity"], reverse=True)

    suggestions = suggestions[:5]

    cache[citation_text] = suggestions
    save_correction_cache(cache)

    return suggestions


def suggest_corrections_for_all():
    """Generate correction suggestions for all unconfirmed citations."""
    api_key = load_api_key()
    unconfirmed_citations = load_unconfirmed_citations()

    low_confidence_citations = [
        c for c in unconfirmed_citations if c.get("confidence", 0) < 0.7
    ]

    logger.info(f"Generating correction suggestions for {len(low_confidence_citations)} unconfirmed citations"
    )

    all_suggestions = {}
    for i, citation in enumerate(low_confidence_citations, 1):
        citation_text = citation.get("citation_text", "")
        if citation_text:
            logger.info(f"[{i}/{len(low_confidence_citations)}] Processing: {citation_text}")
            suggestions = find_similar_citations(citation_text, api_key)

            if suggestions:
                all_suggestions[citation_text] = suggestions
                logger.info(f"  Found {len(suggestions)} suggestions")
            else:
                logger.info("  No suggestions found")

    save_correction_cache(all_suggestions)

    return all_suggestions


def get_correction_suggestions(citation_text):
    """Get correction suggestions for a specific citation."""
    cache = load_correction_cache()

    if citation_text not in cache:
        api_key = load_api_key()
        suggestions = find_similar_citations(citation_text, api_key)
        return suggestions

    return cache[citation_text]


if __name__ == "__main__":
    suggest_corrections_for_all()
