
"""
Citation Correction Suggestions

This module provides functionality to suggest corrections for unconfirmed citations
by finding similar verified citations and providing "did you mean" alternatives.
"""

import refrom src.config import DEFAULT_REQUEST_TIMEOUT, COURTLISTENER_TIMEOUT, CASEMINE_TIMEOUT, WEBSEARCH_TIMEOUT, SCRAPINGBEE_TIMEOUT

import json
import os
import requests
import logging

logger = logging.getLogger(__name__)

try:
    from fuzzywuzzy import fuzz  # type: ignore
except ImportError:
    def fuzz_ratio(s1, s2):
        if not s1 or not s2:
            return 0
        s1, s2 = s1.lower(), s2.lower()
        if s1 == s2:
            return 100
        common_chars = sum(1 for c in s1 if c in s2)
        return int((common_chars / max(len(s1), len(s2))) * 100)
    
    class fuzz:
        @staticmethod
        def ratio(s1, s2):
            return fuzz_ratio(s1, s2)

DOWNLOAD_DIR = "downloaded_briefs"
UNCONFIRMED_CITATIONS_FILE = os.path.join(
    DOWNLOAD_DIR, "unconfirmed_citations_flat.json"
)
CORRECTION_CACHE_FILE = os.path.join(DOWNLOAD_DIR, "correction_suggestions.json")

COURTLISTENER_API_URL = "https://www.courtlistener.com/api/rest/v4/search/"


def load_api_key():
    try:
        with open("config.json", "r") as f:
            config = json.load(f)
            return config.get("courtlistener_api_key")
    except Exception as e:
        logger.error(f"Error loading API key: {e}")
        return None


def load_unconfirmed_citations():
    """Load unconfirmed citations from the JSON file."""
    try:
        if os.path.exists(UNCONFIRMED_CITATIONS_FILE):
            with open(UNCONFIRMED_CITATIONS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        return []
    except Exception as e:
        logger.error(f"Error loading unconfirmed citations: {e}")
        return []


def load_correction_cache():
    """Load correction suggestions from cache."""
    try:
        if os.path.exists(CORRECTION_CACHE_FILE):
            with open(CORRECTION_CACHE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}
    except Exception as e:
        logger.error(f"Error loading correction cache: {e}")
        return {}


def save_correction_cache(cache):
    """Save correction suggestions to cache."""
    try:
        with open(CORRECTION_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache, f, indent=2)
        logger.info(f"Saved correction suggestions to {CORRECTION_CACHE_FILE}")
    except Exception as e:
        logger.error(f"Error saving correction cache: {e}")


def extract_citation_components(citation_text):
    """Extract components from a citation for better matching."""
    components = {}

    volume_match = re.search(r"(\d+)\s+", citation_text)
    if volume_match:
        components["volume"] = volume_match.group(1)

    reporter_match = re.search(r"([A-Za-z]+\.(?:\s*\d+)?[A-Za-z]*)", citation_text)
    if reporter_match:
        components["reporter"] = reporter_match.group(1)

    page_match = re.search(r",\s*(\d+)", citation_text)
    if page_match:
        components["page"] = page_match.group(1)

    year_match = re.search(r"\((\d{4})\)", citation_text)
    if year_match:
        components["year"] = year_match.group(1)

    wl_match = re.search(r"(\d{4})\s+WL\s+(\d+)", citation_text)
    if wl_match:
        components["wl_year"] = wl_match.group(1)
        components["wl_number"] = wl_match.group(2)

    return components


def find_similar_citations(citation_text, api_key=None):
    """Find similar citations using the CourtListener API and local database."""
    cache = load_correction_cache()
    if citation_text in cache:
        logger.info(f"Using cached suggestions for {citation_text}")
        return cache[citation_text]

    suggestions = []

    components = extract_citation_components(citation_text)

    if api_key:
        try:
            query_parts = []
            if "volume" in components:
                query_parts.append(components["volume"])
            if "reporter" in components:
                query_parts.append(components["reporter"])

            if "wl_year" in components and "wl_number" in components:
                query_parts = [f"{components['wl_year']} WL {components['wl_number']}"]

            query = " ".join(query_parts)

            if query:
                headers = {
                    "Authorization": f"Token {api_key}",
                    "Content-Type": "application/json",
                }

                params = {
                    "q": query,
                    "type": "o",  # Opinion type
                    "order_by": "score desc",  # Order by relevance
                    "page_size": 5,  # Limit to 5 results
                }

                logger.info(f"Searching CourtListener API for: {query}")
                response = requests.get(
                    COURTLISTENER_API_URL, headers=headers, params=params, timeout=DEFAULT_REQUEST_TIMEOUT
                )

                if response.status_code == 200:
                    data = response.json()
                    results = data.get("results", [])

                    for result in results:
                        case_name = result.get("case_name", "")
                        citation = result.get("citation", "")
                        url = f"https://www.courtlistener.com{result.get('absolute_url', '')}"

                        if citation:
                            similarity = fuzz.ratio(
                                citation_text,
                                citation,
                            )

                            if similarity > 60:  # Only include if reasonably similar
                                suggestions.append(
                                    {
                                        "citation": citation,
                                        "case_name": case_name,
                                        "url": url,
                                        "similarity": similarity,
                                        "source": "CourtListener API",
                                    }
                                )
        except Exception as e:
            logger.error(f"Error searching CourtListener API: {e}")

    unconfirmed_citations = load_unconfirmed_citations()
    confirmed_citations = [
        c for c in unconfirmed_citations if c.get("confidence", 0) >= 0.7
    ]

    for citation in confirmed_citations:
        confirmed_text = citation.get("citation_text", "")
        if confirmed_text:
            similarity = fuzz.ratio(
                citation_text, confirmed_text
            )

            confirmed_components = extract_citation_components(confirmed_text)
            component_match = False

            if "reporter" in components and "reporter" in confirmed_components:
                if components["reporter"] == confirmed_components["reporter"]:
                    component_match = True

            if (
                "wl_year" in components
                and "wl_year" in confirmed_components
                and components["wl_year"] == confirmed_components["wl_year"]
            ):
                component_match = True

            if similarity > 60 or component_match:
                suggestions.append(
                    {
                        "citation": confirmed_text,
                        "case_name": citation.get("case_name", ""),
                        "url": citation.get("court_listener_url", ""),
                        "similarity": similarity,
                        "source": "Local Database",
                    }
                )

    suggestions.sort(key=lambda x: x["similarity"], reverse=True)

    suggestions = suggestions[:5]

    cache[citation_text] = suggestions
    save_correction_cache(cache)

    return suggestions


def suggest_corrections_for_all():
    """Generate correction suggestions for all unconfirmed citations."""
    api_key = load_api_key()
    unconfirmed_citations = load_unconfirmed_citations()

    low_confidence_citations = [
        c for c in unconfirmed_citations if c.get("confidence", 0) < 0.7
    ]

    logger.info(f"Generating correction suggestions for {len(low_confidence_citations)} unconfirmed citations"
    )

    all_suggestions = {}
    for i, citation in enumerate(low_confidence_citations, 1):
        citation_text = citation.get("citation_text", "")
        if citation_text:
            logger.info(f"[{i}/{len(low_confidence_citations)}] Processing: {citation_text}")
            suggestions = find_similar_citations(citation_text, api_key)

            if suggestions:
                all_suggestions[citation_text] = suggestions
                logger.info(f"  Found {len(suggestions)} suggestions")
            else:
                logger.info("  No suggestions found")

    save_correction_cache(all_suggestions)

    return all_suggestions


def get_correction_suggestions(citation_text):
    """Get correction suggestions for a specific citation."""
    cache = load_correction_cache()

    if citation_text not in cache:
        api_key = load_api_key()
        suggestions = find_similar_citations(citation_text, api_key)
        return suggestions

    return cache[citation_text]


if __name__ == "__main__":
    suggest_corrections_for_all()
